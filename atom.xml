<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://mikey666666.github.io</id>
    <title>Yanhui Chen</title>
    <updated>2023-02-28T01:02:56.138Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://mikey666666.github.io"/>
    <link rel="self" href="https://mikey666666.github.io/atom.xml"/>
    <subtitle>--</subtitle>
    <logo>https://mikey666666.github.io/images/avatar.png</logo>
    <icon>https://mikey666666.github.io/favicon.ico</icon>
    <rights>All rights reserved 2023, Yanhui Chen</rights>
    <entry>
        <title type="html"><![CDATA[CS194-26 Final Project]]></title>
        <id>https://mikey666666.github.io/post/cs194-26-final-project/</id>
        <link href="https://mikey666666.github.io/post/cs194-26-final-project/">
        </link>
        <updated>2022-12-12T08:39:34.000Z</updated>
        <content type="html"><![CDATA[<p>CS194-26: Image Manipulation and Computational Photography</p>
<p>Fall 2022</p>
<p>Yanhui Chen</p>
<p>Project 1: Lightfield Camera</p>
<p>Overview:<br>
Lightfields have set of images of an object captured by the same angle. We will &quot;correct&quot; the off-centered images by using lightfield depth refocusing and aperture adjustment</p>
<p>Depth Refocusing:<br>
Depth refocusing switches focus from one part to another.<br>
<img src="https://mikey666666.github.io/post-images/1671007428876.gif" alt="" loading="lazy"></p>
<p>Aperture Adjustment<br>
Aperture adjustment selects all the image around the center with the radius defined<br>
<img src="https://mikey666666.github.io/post-images/1671007822122.gif" alt="" loading="lazy"><br>
(Radius: 0-8)</p>
<p>Project 2: Image Quilting for Texture Transfer</p>
<p>Overview: Image quilting is a technique of stitching the patches of texture image to others by texture synthesis that generates large textures and texture transfer that re-rendering an image.</p>
<p>random method<br>
<img src="https://mikey666666.github.io/post-images/1671008887492.png" alt="" loading="lazy"></p>
<p>Overlapping method<br>
<img src="https://mikey666666.github.io/post-images/1671009008461.png" alt="" loading="lazy"></p>
<p>Seam-finding cut<br>
<img src="https://mikey666666.github.io/post-images/1671008971886.png" alt="" loading="lazy"></p>
<p>Texture Synthesis:<br>
minimium cost path:<br>
<img src="https://mikey666666.github.io/post-images/1671009137551.png" alt="" loading="lazy"><br>
sythesized image:<br>
<img src="https://mikey666666.github.io/post-images/1671009132813.png" alt="" loading="lazy"></p>
<p>algorithm:</p>
<ol>
<li>Randomly choose block</li>
<li>find least overlap error</li>
<li>cut the error boundary</li>
</ol>
<p>Texture transfer:<br>
Source:<br>
<img src="https://mikey666666.github.io/post-images/1671009253831.png" alt="" loading="lazy"><br>
<img src="https://mikey666666.github.io/post-images/1671009259806.png" alt="" loading="lazy"><br>
Quilting:<br>
<img src="https://mikey666666.github.io/post-images/1671009237914.png" alt="" loading="lazy"></p>
<p>Source:<br>
<img src="https://mikey666666.github.io/post-images/1671009306335.png" alt="" loading="lazy"><br>
<img src="https://mikey666666.github.io/post-images/1671009318577.png" alt="" loading="lazy"><br>
Quilting:<br>
<img src="https://mikey666666.github.io/post-images/1671009339813.png" alt="" loading="lazy"></p>
<p>Blending:<br>
<img src="https://mikey666666.github.io/post-images/1671009381842.png" alt="" loading="lazy"></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[CS194-26 Project 5]]></title>
        <id>https://mikey666666.github.io/post/cs194-26-project-5/</id>
        <link href="https://mikey666666.github.io/post/cs194-26-project-5/">
        </link>
        <updated>2022-11-14T08:06:14.000Z</updated>
        <content type="html"><![CDATA[<p>CS194-26: Image Manipulation and Computational Photography</p>
<p>Fall 2022</p>
<p>Project 5: Facial Keypoint Detection with Neural Networks</p>
<p>Yanhui Chen</p>
<p>Part1:<br>
MSE loss plot:<br>
<img src="https://mikey666666.github.io/post-images/1668586656646.jpg" alt="" loading="lazy"><br>
Ground truth pcitures and best prediction plot:<br>
<img src="https://mikey666666.github.io/post-images/1668586931139.jpg" alt="" loading="lazy"><br>
Ground truth pcitures and worst prediction plot:<br>
<img src="https://mikey666666.github.io/post-images/1668586952118.jpg" alt="" loading="lazy"></p>
<p>Part2:<br>
Sampled image from dataloader visualized with ground-truth keypoints<br>
<img src="https://mikey666666.github.io/post-images/1668586997711.jpg" alt="" loading="lazy"><br>
<img src="https://mikey666666.github.io/post-images/1668587004762.jpg" alt="" loading="lazy"><br>
<img src="https://mikey666666.github.io/post-images/1668587011658.jpg" alt="" loading="lazy"><br>
training and validation loss across iterations<br>
<img src="https://mikey666666.github.io/post-images/1668587063605.jpg" alt="" loading="lazy"><br>
Utilize five square convolution kernels with one input channel and 12 ouput channrels and two linear affine operations as the model.<br>
Best prediction:<br>
<img src="https://mikey666666.github.io/post-images/1668587383891.jpg" alt="" loading="lazy"><br>
Worst prediction:<br>
<img src="https://mikey666666.github.io/post-images/1668587408024.jpg" alt="" loading="lazy"><br>
Those cases fail because the the faces captured are not toward to the camera and the keypoints are hard to detect due to different frame angle.<br>
Visualize the learned filters:<br>
convolution 1:<br>
<img src="https://mikey666666.github.io/post-images/1668587735429.jpg" alt="" loading="lazy"><br>
convolution 2:<br>
<img src="https://mikey666666.github.io/post-images/1668587769074.jpg" alt="" loading="lazy"><br>
convolution 3:<br>
<img src="https://mikey666666.github.io/post-images/1668587775080.jpg" alt="" loading="lazy"><br>
convolution 4:<br>
<img src="https://mikey666666.github.io/post-images/1668587779983.jpg" alt="" loading="lazy"><br>
convolution 5:<br>
<img src="https://mikey666666.github.io/post-images/1668587810976.jpg" alt="" loading="lazy"></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[CS 194-26 Project 4]]></title>
        <id>https://mikey666666.github.io/post/cs-194-26-project-4/</id>
        <link href="https://mikey666666.github.io/post/cs-194-26-project-4/">
        </link>
        <updated>2022-10-10T11:35:11.000Z</updated>
        <content type="html"><![CDATA[<p>CS194-26: Image Manipulation and Computational Photography</p>
<p>Fall 2022</p>
<p>Project 4A: IMAGE WARPING and MOSAICING</p>
<p>Yanhui Chen</p>
<ol>
<li>
<p>Shoot the image<br>
<img src="https://mikey666666.github.io/post-images/1665617788139.jpg" alt="" loading="lazy"><br>
Heast minning left<br>
<img src="https://mikey666666.github.io/post-images/1665617794644.jpg" alt="" loading="lazy"><br>
Heast minning right<br>
<img src="https://mikey666666.github.io/post-images/1665712247016.jpg" alt="" loading="lazy"><br>
study room left<br>
<img src="https://mikey666666.github.io/post-images/1665712261353.jpg" alt="" loading="lazy"><br>
study room right</p>
</li>
<li>
<p>Recover Homographies<br>
<img src="https://mikey666666.github.io/post-images/1665617935998.jpg" alt="" loading="lazy"><br>
<img src="https://mikey666666.github.io/post-images/1665617978212.jpg" alt="" loading="lazy"><br>
Above are the equations to solve for homography matrix</p>
</li>
<li>
<p>Warp the image<br>
<img src="https://mikey666666.github.io/post-images/1665618293694.png" alt="" loading="lazy"><br>
Here is the Heast minning labeled point image<br>
<img src="https://mikey666666.github.io/post-images/1665618302202.png" alt="" loading="lazy"><br>
Above is the warped left image and the original right image<br>
<img src="https://mikey666666.github.io/post-images/1665712362563.png" alt="" loading="lazy"><br>
Here is the study room labeled point image<br>
<img src="https://mikey666666.github.io/post-images/1665712382228.png" alt="" loading="lazy"><br>
Above is the warped left image and the original right image</p>
</li>
<li>
<p>Blend the image into a mosaic<br>
<img src="https://mikey666666.github.io/post-images/1665618398104.png" alt="" loading="lazy"><br>
Blended Heast minning<br>
<img src="https://mikey666666.github.io/post-images/1665712473545.png" alt="" loading="lazy"><br>
Blended Study room</p>
</li>
</ol>
<p>What I learned :<br>
Stitching process and warp process also need to consider the color of the distortion, and interp2 is a good function to use instead of loopping every pixels and transformed by homography matrix.</p>
<p>Project 4B: FEATURE MATCHING for AUTOSTITCHING</p>
<p>Implementing Feature Matching:<br>
<img src="https://mikey666666.github.io/post-images/1666707754860.png" alt="" loading="lazy"><br>
<img src="https://mikey666666.github.io/post-images/1666707760844.png" alt="" loading="lazy"></p>
<p>4-point RANSAC Loop:<br>
Inliers were repeated, and over-compressed image for faster finding the 500 points to warp.</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[CS194-26 Project3]]></title>
        <id>https://mikey666666.github.io/post/cs194-26-project3/</id>
        <link href="https://mikey666666.github.io/post/cs194-26-project3/">
        </link>
        <updated>2022-10-03T01:05:22.000Z</updated>
        <content type="html"><![CDATA[<p>CS194-26: Image Manipulation and Computational Photography</p>
<p>Fall 2022</p>
<p>Project 3: Face Morphing</p>
<p>Yanhui Chen</p>
<p>Part 1: Defining Correspondences<br>
<img src="https://mikey666666.github.io/post-images/1664867350880.png" alt="" loading="lazy"></p>
<p>Part2: Computing the &quot;Mid-way Face&quot;<br>
<img src="https://mikey666666.github.io/post-images/1664867375177.png" alt="" loading="lazy"></p>
<p>Part3: The Morph Sequence<br>
<img src="https://mikey666666.github.io/post-images/1664867401127.png" alt="" loading="lazy"></p>
<p>GIF:<br>
<img src="https://mikey666666.github.io/post-images/1664867422557.gif" alt="" loading="lazy"></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[CS 194-26 Project 2]]></title>
        <id>https://mikey666666.github.io/post/cs-194-26-project2/</id>
        <link href="https://mikey666666.github.io/post/cs-194-26-project2/">
        </link>
        <updated>2022-09-13T16:25:44.000Z</updated>
        <content type="html"><![CDATA[<p>CS194-26: Image Manipulation and Computational Photography</p>
<p>Fall 2022</p>
<p>Project 2: Fun with Filters and Frequencies!</p>
<p>Yanhui Chen</p>
<p>Part 1: Fun with Filters<br>
Part 1.1: Finite Difference Operator</p>
<p><img src="https://mikey666666.github.io/post-images/1663652495749.png" alt="" loading="lazy"><br>
<img src="https://mikey666666.github.io/post-images/1663652502502.png" alt="" loading="lazy"><br>
The partial derivative with x,y direction and combine together and suppress the noise</p>
<p>Part 1.2: Derivative of Gaussian (DoG) Filter<br>
<img src="https://mikey666666.github.io/post-images/1663652817095.png" alt="" loading="lazy"><br>
<img src="https://mikey666666.github.io/post-images/1663652857366.png" alt="" loading="lazy"><br>
We can see clearer edges across the specific gradient direction of the low frequency image, and only the low frequency part shown by the filter.</p>
<p><img src="https://mikey666666.github.io/post-images/1663653284106.png" alt="" loading="lazy"><br>
We confimed that we have same results by comparing one convolution and two convolutions.<br>
Two convolutions: do blurred convolutions on image first then take the gradient convolutions<br>
One convolutions: Create a derivative of gaussian filter then do one convolutions on image</p>
<p>Part 2: Fun with Frequencies!<br>
Part 2.1: Image &quot;Sharpening&quot;</p>
<p>Sample result:<br>
<img src="https://mikey666666.github.io/post-images/1663653458996.png" alt="" loading="lazy"><br>
The edges and detail patterns of the temple are more clearer.</p>
<p>My selection result:<br>
<img src="https://mikey666666.github.io/post-images/1663653477381.png" alt="" loading="lazy"><br>
Nezuko is more sharpened.</p>
<p>Part 2.2: Hybrid Images<br>
Sample hybrid result:<br>
<img src="https://mikey666666.github.io/post-images/1663653661865.png" alt="" loading="lazy"><br>
Using color works better for both</p>
<p>My selection hybrid result:<br>
<img src="https://mikey666666.github.io/post-images/1663653940791.png" alt="" loading="lazy"><br>
<img src="https://mikey666666.github.io/post-images/1663653948307.png" alt="" loading="lazy"></p>
<p>Part 2.4: Multiresolution Blending (a.k.a. the oraple!)</p>
<p>1.Implement a Gaussian and a Laplacian stack<br>
2.Create a half ones and half zeros mask from left to right<br>
3.Apply Gaussian stack on mask and laplacian stack on images<br>
4.Add the half apple and half orange together after applying mask on images<br>
5.Iterate from the pyramid to increase the level and see a smoother and sharper result<br>
<img src="https://mikey666666.github.io/post-images/1663654059173.png" alt="" loading="lazy"></p>
<p>My selection with blending(left and right)<br>
<img src="https://mikey666666.github.io/post-images/1663654421709.png" alt="" loading="lazy"></p>
<p>My selection with blending(top and bottom)<br>
<img src="https://mikey666666.github.io/post-images/1663654457356.png" alt="" loading="lazy"></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[CS 194-26 Project 1]]></title>
        <id>https://mikey666666.github.io/post/yanhuichen-is-good/</id>
        <link href="https://mikey666666.github.io/post/yanhuichen-is-good/">
        </link>
        <updated>2022-09-03T04:29:45.000Z</updated>
        <content type="html"><![CDATA[<p>CS194-26: Image Manipulation and Computational Photography</p>
<p>Fall 2022</p>
<p>Project 1: Images of the Russian Empire:<br>
Colorizing the Prokudin-Gorskii photo collection</p>
<p>Yanhui Chen</p>
<p>Overview:<br>
The goal of this assignment is to take the digitized Prokudin-Gorskii glass plate images and, using image processing techniques, automatically produce a color image with as few visual artifacts as possible. In order to do this, you will need to extract the three color channel images, place them on top of each other, and align them so that they form a single RGB color image.</p>
<p>Implementation:<br>
&lt; Exhaustive search</p>
<ol>
<li>Focus the optimal window [-15, 15]</li>
<li>Computer the L2 norm Sum of Squared Differences (SSD) distance which is simply sum(sum((image1-image2).^2))</li>
<li>shift the horizontal and vertical displacement and find the smallest SSD</li>
</ol>
<p>&lt; Pyramid search<br>
For high resolution photograph, the large image can be scaled down by a factor of two. Creating the Pyramid search to find the scaling levels and get the desired level.</p>
<p>Results:</p>
<p>Low resolution:<br>
<img src="https://mikey666666.github.io/post-images/1662529606906.jpg" alt="" loading="lazy"><br>
B Alignment = (1,-1)<br>
G Alignment = (0,0) [Reference]<br>
R Alignment = (0,7)</p>
<p><img src="https://mikey666666.github.io/post-images/1662529708012.jpg" alt="" loading="lazy"><br>
B Alignment = (0,6)<br>
G Alignment = (0,0) [Reference]<br>
R Alignment = (1,6)</p>
<p><img src="https://mikey666666.github.io/post-images/1662529761061.jpg" alt="" loading="lazy"><br>
B Alignment = (-2,-3)<br>
G Alignment = (0,0) [Reference]<br>
R Alignment = (1,4)</p>
<p>High resolution:<br>
<img src="https://mikey666666.github.io/post-images/1662529826132.jpg" alt="" loading="lazy"><br>
B Alignment = (8,0)<br>
G Alignment = (0,0) [Reference]<br>
R Alignment = (0,32)</p>
<p><img src="https://mikey666666.github.io/post-images/1662529841269.jpg" alt="" loading="lazy"><br>
B Alignment = (-8,0)<br>
G Alignment = (0,0) [Reference]<br>
R Alignment = (8,112)</p>
<p><img src="https://mikey666666.github.io/post-images/1662529890639.jpg" alt="" loading="lazy"><br>
B Alignment = (0,-120)<br>
G Alignment = (0,0) [Reference]<br>
R Alignment = (0,64)</p>
<p><img src="https://mikey666666.github.io/post-images/1662529970565.jpg" alt="" loading="lazy"><br>
B Alignment = (-16,-40)<br>
G Alignment = (0,0) [Reference]<br>
R Alignment = (0,48)</p>
<p><img src="https://mikey666666.github.io/post-images/1662530004388.jpg" alt="" loading="lazy"><br>
B Alignment = (8,-56)<br>
G Alignment = (0,0) [Reference]<br>
R Alignment = (-8,48)</p>
<p><img src="https://mikey666666.github.io/post-images/1662530060490.jpg" alt="" loading="lazy"><br>
B Alignment = (0,-80)<br>
G Alignment = (0,0) [Reference]<br>
R Alignment = (0,96)</p>
<p><img src="https://mikey666666.github.io/post-images/1662530101033.jpg" alt="" loading="lazy"><br>
B Alignment = (-16,-56)<br>
G Alignment = (0,0) [Reference]<br>
R Alignment = (8,56)</p>
<p><img src="https://mikey666666.github.io/post-images/1662530144990.jpg" alt="" loading="lazy"><br>
B Alignment = (8,-32)<br>
G Alignment = (0,0) [Reference]<br>
R Alignment = (-16,104)</p>
<p><img src="https://mikey666666.github.io/post-images/1662530245760.jpg" alt="" loading="lazy"><br>
B Alignment = (0,-48)<br>
G Alignment = (0,0) [Reference]<br>
R Alignment = (0,96)</p>
<p><img src="https://mikey666666.github.io/post-images/1662530262254.jpg" alt="" loading="lazy"><br>
B Alignment = (-8,-56)<br>
G Alignment = (0,0) [Reference]<br>
R Alignment = (0,56)</p>
<p><img src="https://mikey666666.github.io/post-images/1662530308446.jpg" alt="" loading="lazy"><br>
B Alignment = (8,-112)<br>
G Alignment = (0,0) [Reference]<br>
R Alignment = (0,112)</p>
]]></content>
    </entry>
</feed>